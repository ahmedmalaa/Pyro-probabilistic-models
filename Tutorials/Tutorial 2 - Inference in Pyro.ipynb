{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference in Pyro\n",
    "\n",
    "**This Tutorial is adapted from [https://pyro.ai/examples/intro_part_ii.html](https://pyro.ai/examples/intro_part_ii.html)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much of modern machine learning can be cast as approximate inference and expressed succinctly in a language like Pyro. To motivate the rest of this tutorial, let's build a generative model for a simple physical problem so that we can use Pyro's inference machinery to solve it. However, we will first import the required modules for this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import pyro\n",
    "import pyro.infer\n",
    "import pyro.optim\n",
    "import pyro.distributions as dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we are trying to figure out how much something weighs ($W$), but the scale we're using is unreliable and gives slightly different answers every time we weigh the same object. We could try to compensate for this variability by integrating the noisy measurement ($M$) information with a guess ($G$) based on some prior knowledge about the object, like its density or material properties. The following model encodes this process:\n",
    "\n",
    "$W \\,|\\,G \\sim \\mathcal{N}(G, 1)$\n",
    "\n",
    "$M \\,|\\, W,\\, G\\, \\sim \\mathcal{N}(W,\\frac{3}{4})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this is a model not only for our belief over weight, but also for the result of taking a measurement of it. The model corresponds to the following stochastic function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scale(guess):\n",
    "    \n",
    "    weight = pyro.sample(\"weight\", dist.Normal(guess, 1.0))\n",
    "    \n",
    "    return pyro.sample(\"measurement\", dist.Normal(weight, 0.75))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The real utility of probabilistic programming is in the ability to condition generative models on observed data and infer the latent factors that might have produced that data.** In Pyro, we separate the expression of conditioning from its evaluation via inference, making it possible to write a model once and condition it on many different observations. Pyro supports constraining a modelâ€™s internal sample statements to be equal to a given set of observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the scale example once again. Suppose we want to sample from the distribution of weight given input guess = 8.5, but now we have observed that measurement == 9.5. That is, we wish to infer the distribution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$W\\,|\\,M, G \\sim ?$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pyro provides the function **pyro.condition** to allow us to constrain the values of sample statements. **pyro.condition** is a *higher-order function* that takes a *model* and a *dictionary of observations* and **returns a new model that has the same input and output signatures but always uses the given values at observed sample** statements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conditioned_scale = pyro.condition(scale, data={\"measurement\": 9.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because it behaves just like an ordinary Python function, conditioning can be deferred or parametrized with Python's **lambda** or **def**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deferred_conditioned_scale(measurement, guess):\n",
    "    \n",
    "    return pyro.condition(scale, data={\"measurement\": measurement})(guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases it might be more convenient to pass observations directly to individual **pyro.sample** statements instead of using **pyro.condition**. The optional obs keyword argument is reserved by **pyro.sample** for that purpose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scale_obs(guess):  # equivalent to conditioned_scale above\n",
    "    \n",
    "    weight = pyro.sample(\"weight\", dist.Normal(guess, 1.))\n",
    "     # here we condition on measurement == 9.5\n",
    "    \n",
    "    return pyro.sample(\"measurement\", dist.Normal(weight, 1.), obs=9.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, in addition to **pyro.condition** for incorporating observations, Pyro also contains **pyro.do**, an implementation of Pearl's do-operator used for causal inference with an identical interface to **pyro.condition**. **condition** and **do** can be mixed and composed freely, making Pyro a powerful tool for model-based causal inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flexible Approximate Inference With Guide Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us return to **conditioned_scale**. Now that we have conditioned on an observation of measurement, we can use Pyro's approximate inference algorithms to estimate the distribution over weight given guess and measurement == data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference algorithms in Pyro, such as **pyro.infer.SVI**, allow us to use arbitrary stochastic functions, which we will call guide functions or guides, as approximate posterior distributions. Guide functions must satisfy these two criteria to be valid approximations for a particular model: \n",
    "\n",
    "1. All unobserved (i.e., not conditioned) sample statements that appear in the model appear in the guide. \n",
    "\n",
    "2. The guide has the same input signature as the model (i.e., takes the same arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
